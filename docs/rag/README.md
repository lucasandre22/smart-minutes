# ğŸ” Understanding Retrieval-Augmented Generation (RAG)

## ğŸ“Œ What is RAG?

**Retrieval-Augmented Generation (RAG)** is a technique that enhances Large Language Models (LLMs) by incorporating **external knowledge retrieval**. In the context of this project, the external knowledge can be documents, manuals, laws, etc.

Instead of relying solely on pre-trained knowledge, RAG retrieves **relevant documents** from a vector database (FAISS) and uses them to **generate more accurate and context-aware responses**.

## âš™ï¸ How Does RAG Work?

The RAG process follows these main steps:

1ï¸âƒ£ **User Query** â†’ The system receives an input query.
2ï¸âƒ£ **Document Retrieval** â†’ A vector database (FAISS) finds relevant documents based on semantic similarity.  
3ï¸âƒ£ **Context Injection** â†’ The retrieved documents are provided as context to the LLM.
4ï¸âƒ£ **Response Generation** â†’ The LLM generates a response.

## ğŸ—ï¸ Why Use RAG?

âœ… **Improves Accuracy** â€“ Uses external knowledge to enhance responses.  
âœ… **Reduces Hallucinations** â€“ The model grounds its output in real, verifiable data.  
âœ… **Dynamic Knowledge Updates** â€“ New information can be added without retraining the LLM. 

## SmartMinutes RAG workflow

The following diagram demonstrates the RAG workflow in the context of the system:

![RagWorkflow](../../assets/rag.png)